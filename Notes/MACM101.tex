\documentclass[12pt]{article}
\usepackage{amsmath}
%\usepackage{systeme}
\usepackage{amsthm}
\usepackage{array}
\usepackage{algpascal}
\usepackage{amssymb}
\usepackage{circuitikz}
\usepackage{adjustbox}
\usepackage[shortlabels]{enumitem}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newtheorem{definition}{Definition} [section]
\newtheorem{proposition}{Proposition} [subsection]
\newtheorem{theorem}{Theorem} [section]
\newtheorem{corollary}{Corollary} [theorem]

\title{MACM 101}
\author{Dr. C. Kay Wiese}
\date{}

\begin{document}

\maketitle

\section{Counting}

\subsection{The Rules of Sums and Products}

Be careful of initial conditions (duplicates and assumptions)
\\
\underline{Rules of Sums}

If task A can be performed in $m$ ways, while task B can be performed in $n$ ways and A and B cannot be done simultaneously, then performing either task can be done in any one of $m+n$ ways
\\
\underline{Rules of Products}

A procedure P can be broken down into A and B stage. If A has $m$ outcomes and B has $n$ outcomes, P can be carried out in $m * n$ ways.
\subsection{Permutations}
\begin{itemize}
\item Distinct Objects
\item Linear arrangement objects, i.e.\ the \emph{order} of objects is important
\end{itemize}
\begin{definition}Factorials\end{definition} For integer $n \geq 0$,
\[
n!=\begin{cases} 1 & n=0 \\ n*(n-1)!&n\geq1\end{cases}
\]
\begin{definition}\end{definition} \noindent If there are $n$ distinct objects and $ 1 \leq r \leq n $, then, by rule of product, the number of permutations of size $r$ for the $n$ objects is
\[
P(n, r) = \frac{n!}{(n-r)!}
\]
\subsection{Combinations}
\begin{definition}\end{definition} \noindent If there are $n$ distinct objects and $ 1 \leq r \leq n $, then the number of combinations of size $r$ for the $n$ objects is
\[
\binom{n}{k}=C(n, r) = \frac{n!}{(n-r)!r!}
\]
\\
You can use a combinatorial argument in proofs.
\begin{proposition} For positive integers $n$ and $k$ with $n=2k, \frac{n!}{2!^k}$ is an integer. \end{proposition}
\emph{Proof.}  Consider the $n$ symbols: $x_1, x_1, x_2, x_2, \cdots, x_k, x_k$.
The number of arrangements of all these $n = 2k$ symbols is an integer that equals
\[
\frac{n!}{\underbrace{2! 2! \cdots 2!}_{\text{k factors of 2!}}} = \frac{n!}{2!^k}
\]
\begin{definition}Sigma notation\end{definition}
\[
a_m + a_{m+1} + a_{m+2} + \cdots + a_{m+n} = \sum_{i = m}^{m+n} a_i
\]
\begin{definition}Weight\end{definition}
Weight of a string $X = x_1 x_2 \dots x_n$ is defiined as wt($X$) = $\sum_{i=1}^n x_i$
\begin{theorem}Binomial Theorem\end{theorem}
\[
(x+y)^n = \sum_{i=0}^{n} \binom{n}{i} x^i y^{n-i}
\]
\begin{corollary}\end{corollary} Set $x=y=1$, then it follows that 
\[
\sum_{i=0}^n \binom{n}{i} = 2^n
\]
\begin{corollary}\end{corollary} Similary, set $x = -1$ and $y = 1$, then it follows that 
\[
\sum_{i=0}^n -1^i \binom{n}{i} = 0
\]
\begin{theorem}Multinomial Theorem\end{theorem} With integers $n, t > 0$, the coefficient of $ x_1^{n_1}x_2^{n_2}\cdots x_t^{n_t}$ in the expansion of $(x_1 + x_2 + \cdots + x_t)^n$ is
\[
\frac{n!}{n_1!n_2! \cdots n_t!} = \binom{n}{n_1, n_2, \cdots n_t}
\]
where each $n_i$ is an integer with $0 \leq n_i \leq n$, for all $1 \leq i \leq t$, and $n_1 + n_2 + \cdots + n_t = n$.\\

\emph{Proof.} Choose $x_1$ from $n_1$ out of $n$ factors, then choose $x_2$ from $n_2$ out of $n - n_1$ factors, and so on. This gives 
\begin{eqnarray*}
& \displaystyle \binom{n}{n_1} \binom{n-n_1}{n_2} \binom{n-n_1-n_2}{n_3} \cdots \binom{n-n_1-n_2- \cdots - n_{t-1}}{n_t} \\
= & \displaystyle \frac{n!}{n_1!(n-n_1)!} \frac{(n-n_1)!}{n_2!(n-n_1-n_2)!} \cdots \frac{(n-n_1-n_2- \cdots - n_{t-1})!}{n_t!(n-n_1-n_2- \cdots - n_{t-1}-n_t)!} \\
= & \displaystyle \frac{n!}{n_1!n_2! \cdots n_t!}
\end{eqnarray*}
\subsection{Combinations with Repetition}
The number of ways to select $r$ of $n$ distinct objects with repetitions is
\[
\binom{n+r-1}{r}
\]
It is equivalent to the number of ways to separate $r$ identical stones with $n-1$ identical sticks where there are $n$ slots to represent how many times the $n$th object was chosen with the number of stones. 

Same logic can be used for counting how many ways $r$ objects can be distributed to $n$ containers, or how many ways $n$ nonnegative integers can add up to $r$ (order matters).

You can also count the number of execution of such codes:
\begin{algorithmic}
\State $counter := 0;$
\For{i=1}{n}
\For{j=1}{i}
\For{k=1}{j}
\State $counter := counter + 1;$
\end{algorithmic}
It is equivalent to counting how many triples of $(i, j, k)$ satisfy $1 \leq k \leq j \leq i \leq n$, which is choosing 3 numbers from $n$ numbers with repetitions. $counter$ would be $\displaystyle \binom{n+3-1}{3}$.
\pagebreak
\section{Fundamentals of Logic}
\subsection{Basic Connectives and Truth Tables}
\begin{definition}{\emph{Declarative sentences that are either true or false are called} statements\emph{(or} propositions\emph{), and we use lowercase letters of the alphabet to represent such statements.}}
\end{definition}
\emph{Primitive} statements cannot be broken down into anything simpler, and new statements can be obtained from existing ones in two ways.
\begin{enumerate}
\item Transform a given statement $p$ to $\neg p$ (Not $p$).\\
\item Combine two or more statements into a \emph{compound} statement, using one of the \emph{logical connectives}.
\begin{enumerate}
\item Conjunction: $p \wedge q$ ($p$ and $q$)
\item Disjunction: 
\begin{enumerate}
\item$p \vee q$ ($p$ or $q$)
\item $p \veebar q$
\end{enumerate}
\item Implication: $p \rightarrow q$ ($p$ implies $q$)
\item Biconditional: $p \leftrightarrow q$ ($p$ if and only if $q$)
\end{enumerate}
\end{enumerate}
Here is the truth table.\footnote{Sometimes, 0 and 1 are used for F and T instead, similar to bit-logic.}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$p$ & $q$ & $p \wedge q$ & $p \vee q$ & $p \veebar q$ & $p \rightarrow q$ & $p \leftrightarrow q$ \\
\hline
T & T & T & T & F & T & T \\
\hline
T & F & F & T & T & F & F \\
\hline
F & T & F & T & T & T & F \\
\hline
F & F & F & F & F & T & T \\
\hline
\end{tabular}
\end{center}
\begin{definition}
\emph{A compound statement is called a} tautology \emph{if it is always true. If it is always false, it is called a }contradiction. 
\end{definition}
We use the symbol $T_0$ to denote any tautology and the symbol $F_0$ to denote any contradiction.
\subsection{Logical Equivalence: The Laws of Logic}
\begin{definition}\emph{Two statements $s_1, s_2$ are said to be }logically equivalent \emph{when $s_1 \leftrightarrow s_2$, and we write $s_1 \Leftrightarrow s_2$}.
\end{definition}
\noindent If 2 statements are not logically equivalent, we write $s_1 \nLeftrightarrow s_2 \quad (\neg(s_1 \Leftrightarrow s_2))$.
\begin{center}
\textbf{The Laws of Logic}
\end{center}
\begin{tabular}  {c l l}
1) & $\neg \neg p \Leftrightarrow p$ & Law of Double Negation\\
2) & $\neg (p \wedge q) \Leftrightarrow \neg p \vee \neg q$ & DeMorgan's Laws\\
& $\neg (p \vee q) \Leftrightarrow \neg p \wedge \neg q$\\
3) & $p \wedge q \Leftrightarrow q \wedge p$ & Commutative Laws\\
& $p \vee q \Leftrightarrow q \vee p$\\
4) & $(p \wedge q) \wedge r \Leftrightarrow p \wedge (q \wedge r)$ & Associative Laws\\
& $(p \vee q) \vee r \Leftrightarrow p \vee (q \vee r)$\\
5) & $p \wedge (q \vee r) \Leftrightarrow (p \wedge q) \vee (p \wedge r)$ & Distributive Laws\\
& $p \vee (q \wedge r) \Leftrightarrow (p \vee q) \wedge (p \vee r)$\\
6) & $p \vee p \Leftrightarrow p$ & Idempotent Laws\\
& $p \wedge p \Leftrightarrow p$\\
7) & $p \vee F_0 \Leftrightarrow p$ & Identity Laws\\
& $p \wedge T_0 \Leftrightarrow p$\\
8) & $p \vee \neg p \Leftrightarrow T_0$ & Inverse Laws\\
& $p \wedge \neg p \Leftrightarrow F_0$\\
9) & $p \wedge F_0 \Leftrightarrow F_0$ & Domination Laws\\
& $p \vee T_0 \Leftrightarrow T_0$\\
10) & $p \vee (p \wedge q) \Leftrightarrow p$ & Absorption Laws\\
& $p \wedge (p \vee q) \Leftrightarrow p$
\end{tabular}
\\ \\
Following statements are also equivalent.
\begin {enumerate}
\item $p \rightarrow q \Leftrightarrow \neg p \vee q$
\item $p \leftrightarrow q \Leftrightarrow (p \rightarrow q) \wedge (q \rightarrow p) \Leftrightarrow (\neg p \vee q) \wedge (\neg q \vee p)$
\item $p \veebar q \Leftrightarrow (p \vee q) \wedge \neg (p \wedge q)$
\end{enumerate}
Using the above logival equivalences, we can eliminate those three connectives$(\rightarrow, \leftrightarrow, \veebar)$ from any logical compound statements.
\pagebreak
\begin{definition}
\emph{Let $s$ be a statement containing only $\wedge$ and $\vee$ as logical connectives. The dual of $s$, denoted $s^d$, is derived from $s$ by replacing each $\wedge$ with $\vee$, $\vee$ with $\wedge$, $T_0$ with $F_0$, and $F_0$ with $T_0$.}
\end{definition}
\noindent If $p$ is a primitive statement, then $p_d$ is the same as p.
\[
p = p^d
\]
\begin{theorem}
The Principle of Duality. \emph{Let $s$ and $t$ be statements containing no logical connectives other than $\wedge$ and $\vee$. If $s \Leftrightarrow t$, then $s^d \Leftrightarrow t^d$}.
\end{theorem}
\subsubsection{The Subtitution Rules}
\begin{enumerate}
\item Suppose, compound statement $P$ is a tautology. If $p$ is a primitive statement that appears in $P$ and we replace all occurrences of $p$ by an arbitrary statement $q$, then the resulting compound statement $P_1$ is also a tautology.
\item $P$ is a compound statement, $p$ is an arbitrary statement that appears in $P$, let $q$ be a statement such that $p \Leftrightarrow q$. Now replace 1 or more occurrences of $p$ by $q$, this yields $P_1$. Now, $P_1 \Leftrightarrow P$.
\end{enumerate}

\subsubsection{Relatives of the Implication $p \rightarrow q$}
\begin{tabular}{l c}
Inverse: & $\neg p \rightarrow \neg q$\\
Converse: & $q \rightarrow p$\\
Contrapositive: & $\neg q \rightarrow \neg p$\\
\end{tabular}
\begin{center}
\begin{tabular}{c l l}
1) & $p \rightarrow q \Leftrightarrow \neg q \rightarrow \neg p$ & Implication $\Leftrightarrow$ Contrapositive\\
2) & $q \rightarrow p \Leftrightarrow \neg p \rightarrow \neg q$ & Converse $\Leftrightarrow$ Inverse\\
3) & $p \rightarrow q \nLeftrightarrow q \rightarrow p$ & Implication $\nLeftrightarrow$ Converse\\
4) & $\neg p \rightarrow \neg q \nLeftrightarrow \neg q \rightarrow \neg p$ & Contrapositive $\nLeftrightarrow$ Inverse
\end{tabular}
\end{center}

\noindent An implication is logically equivalent to its contrapositive, but not to its inverse or converse. At the same time, its inverse and converse are logically equivalent. \\\\
(\emph{Note:} The negation of an it-then statement (in words) does not begin with the word if. i.e. it is not another implication.)
\subsubsection{Applications: Simplifying Switching Networks}
A switching network is made up of wires and switches connecting two Terminals $T_1$ and $T_2$. In such a network, each switch is either open (0) so current doesn't flow, or closed (1) so current does flow through it. Switches in \emph{parallel} are represented by $\vee$, and switches in \emph{series} are represented by $\wedge$.
\begin{center}
\begin{circuitikz} \draw
(0,1) node[left] {$T_1$}

(0,1) to (1,1)
(1,2) to[normal closed switch, l=$p$] (3,2)
(1,2) to (1,1)
(3,2) to (3,1)
(1,1) to[normal closed switch, l=$q$] (3,1)
(1,0) to (1,1)
(3,0) to (3,1)
(1,0) to[normal closed switch, l=$r$] (3,0)
(3,1) to (4,1)

(3,1) to (3,1)
(4,2) to[normal closed switch, l=$p$] (6,2)
(4,2) to (4,1)
(6,2) to (6,1)
(4,1) to[normal closed switch, l=$t$] (6,1)
(4,0) to (4,1)
(6,0) to (6,1)
(4,0) to[normal closed switch, l=$\neg q$] (6,0)
(6,1) to (7,1)

(6,1) to (6,1)
(7,2) to[normal closed switch, l=$p$] (9,2)
(7,2) to (7,1)
(9,2) to (9,1)
(7,1) to[normal closed switch, l=$\neg t$] (9,1)
(7,0) to (7,1)
(9,0) to (9,1)
(7,0) to[normal closed switch, l=$r$] (9,0)
(9,1) to (10,1)

(10,1) node[right] {$T_2$}
;
\end{circuitikz}
\end{center}
Such network can be represented by the statement $(p \vee q \vee r) \wedge (p \vee t \vee \neg q) \wedge (p \vee \neg t \vee r)$. This can be simplified using the laws of logic.
\begin{center}
\begin{tabular} {l l l}
& $(p \vee q \vee r) \wedge (p \vee t \vee \neg q) \wedge (p \vee \neg t \vee r)$ & \textbf{Reasons}\\
$\Leftrightarrow$ & $p \vee [(q \vee r) \wedge (t \vee \neg q) \wedge (\neg t \vee r)]$ & Distributive Law of $\wedge$ over $\vee$\\
$\Leftrightarrow$ & $p \vee [(q \vee r) \wedge (\neg t \vee r) \wedge (t \vee \neg q)]$ & Commutative Law of $\wedge$\\
$\Leftrightarrow$ & $p \vee [((q \wedge \neg t) \vee r) \wedge (t \vee \neg q)]$ & Distributive Law of $\wedge$ over $\vee$\\
$\Leftrightarrow$ & $p \vee [((q \wedge \neg t) \vee r) \wedge (\neg \neg t \vee \neg q)]$ & Law of Double Negation\\
$\Leftrightarrow$ & $p \vee [((q \wedge \neg t) \vee r) \wedge \neg (\neg t \wedge q)]$ & DeMorgan's Law\\
$\Leftrightarrow$ & $p \vee [\neg (\neg t \wedge q) \wedge ((\neg t \wedge q) \vee r)]$ & Commutative Law of $\wedge$\\
$\Leftrightarrow$ & $p \vee [(\neg (\neg t \wedge q) \wedge (\neg t \wedge q)) \vee (\neg (\neg t \wedge q) \wedge r)]$ & Distributive Law of $\wedge$ over $\vee$\\
$\Leftrightarrow$ & $p \vee [F_0 \vee (\neg (\neg t \wedge q) \wedge r)]$ & $s \wedge \neg s \Leftrightarrow F_0$ for any statement $s$\\
$\Leftrightarrow$ & $p \vee [\neg (\neg t \wedge q) \wedge r]$ & $F_0$ is the Identity for $\vee$\\
$\Leftrightarrow$ & $p \vee [r \wedge \neg (\neg t \wedge q)]$ & Commutative Law of $\wedge$\\
$\Leftrightarrow$ & $p \vee [r \wedge (t \vee \neg q)]$ & DeMorgan's Law and \\
&&the Law of Double Negation
\end{tabular}
\end{center}
\subsection{Logical Implication: Rules of Inference}
We show an argument with premises $(p_1, p_2, \cdots, p_n)$ and conclusion $q$ is valid by showing the following implication is a tautology:
\[
(p_1 \wedge p_2 \wedge \cdots \wedge p_n) \rightarrow q
\]
To show the following implication is a tautology, we need to show that $q$ is true if all the premises are true.

You can incorporate this into an automatic "inference engine", the basic component of an AI expert system. These systems combine basic facts to develop more facts.
\begin{definition}
\emph{If $p, q$ are arbitrary statements such that $p \rightarrow q$ is a tautology, then we say that $p$} logically implies \emph{$q$ and we write $p \Rightarrow q$ to denote this situation.}
\end{definition}
The notation $p \nRightarrow q$ is used to indicate that $p \rightarrow q$ is \emph{not} a tautology --- so the given implication ($p \rightarrow q$) is not a logical implication.
If $p \Leftrightarrow q$, then $p \leftrightarrow q$ is a tautology. This means $p \rightarrow q$ and $q \rightarrow p$ are tautologies, too, thus $p \Rightarrow q$ and $q \Rightarrow p$. The converse is also true.

When establishing the validity of an argument, the rules of inferences will enable us to consider only the cases wherein all the premises are true. They are fundamental in the development of a step-by-step validation of how the conclusion $q$ logically follows from the premises $p_1, p_2, \cdots , p_n$ in an implication of the form \[(p_1 \wedge p_2 \wedge \cdots \wedge p_n) \rightarrow q.\] This development will establish the validity of the given arguement, for it will show how the truth of the conclusion can be deduced from the truth of the premises.
\begin{center}
\addtolength{\leftskip} {-2cm} % increase (absolute) value if needed
\addtolength{\rightskip}{-2cm}
%\textbf{\large Rules of Inference}
\begin{tabular} {|l |l| l| C{4cm}|}
\hline
& \textbf{Rule of Inference} & \textbf{Related Logical Implication} & \textbf{Name of Rule}\\
\hline
1) & \begin{tabular} {c l}& $p$\\& $p \rightarrow q$\\\hline$\therefore$ & $q$\end{tabular} & $[p \wedge (p \rightarrow q)] \rightarrow q$ & Rule of Detachment / Modus Ponens\\
\hline
2) & \begin{tabular} {c l}& $p \rightarrow q$\\& $q\rightarrow r$\\\hline$\therefore$ & $p \rightarrow r$\end{tabular} & $[(p \rightarrow q) \vee (q \rightarrow r)] \rightarrow (p \rightarrow r)$ & Law of the Syllogism\\
\hline
3) & \begin{tabular} {c l}& $p \rightarrow q$\\& $\neg q$\\\hline$\therefore$ & $\neg p$\end{tabular} & $[(p \rightarrow q) \wedge \neg q)] \rightarrow \neg p$ &Modus Tollens \\
\hline
4) & \begin{tabular} {c l}& $p$\\& $q$\\\hline$\therefore$ & $p \wedge q$\end{tabular} & & Rule of Conjunction\\
\hline
5) & \begin{tabular} {c l}
& $p \vee q$\\
& $\neg p$\\
\hline
$\therefore$ & $q$
\end{tabular} & $[(p \vee q) \wedge \neg p] \Rightarrow q$ & Rule of Disjunctive Syllogism\\
\hline
6) & \begin{tabular} {c l}
& $\neg p \rightarrow F_0$\\
\hline
$\therefore$ & $p$
\end{tabular}
 & $(\neg p \rightarrow F_0) \rightarrow p$ & Rule of Contradiction\\
\hline
7) & \begin{tabular} {c l}
& $p \wedge q$\\
\hline
$\therefore$ & $p$
\end{tabular}
 & $(p \wedge q) \rightarrow p$ & Rule of Conjunctive Simplification\\
\hline
8) & \begin{tabular} {c l}
& $p$\\
\hline
$\therefore$ & $p \vee q$
\end{tabular}
 & $p \rightarrow p \vee q$ & Rule of Disjunctive Amplification\\
\hline
9) & \begin{tabular} {c l}
& $p \wedge q$\\
& $p \rightarrow (q \rightarrow r)$\\
\hline
$\therefore$ & $r$
\end{tabular}
 & $[(p \wedge q) \wedge [p \rightarrow (q \rightarrow r)]] \rightarrow r$ & Rule of Conditional Proof\\
\hline
10) & \begin{tabular} {c l}
& $p \rightarrow r$\\
& $q \rightarrow r$\\
\hline
$\therefore$ & $(p \vee q) \rightarrow r$
\end{tabular}
 & $[(p \rightarrow r) \wedge (q \rightarrow r)] \rightarrow [(p \vee q) \rightarrow r]$ & Rule for Proof Cases\\
\hline
11) & \begin{tabular} {c l}
& $p \rightarrow q$\\
& $r \rightarrow s$\\
& $p \vee r$\\
\hline
$\therefore$ & $q \vee s$
\end{tabular}
 & $[(p \rightarrow q) \wedge (r \rightarrow s) \wedge (p \vee r)] \rightarrow (q \vee s)$ & Rule of the Constructive Dilemma\\
\hline
12) & \begin{tabular} {c l}
& $p \rightarrow q$\\
& $r \rightarrow s$\\
& $\neg q \vee \neg s$\\
\hline
$\therefore$ & $\neg p \vee \neg r$
\end{tabular}
 & $[(p \rightarrow q) \wedge (r \rightarrow s) \wedge (\neg q \vee \neg s)] \rightarrow (\neg p \vee \neg r)$ & Rule of Destructive Dilemma\\
\hline
\end{tabular}
\end{center}
\pagebreak
The Rule of Contradiction is the basis of a method of \emph{Proof by Contradiction}, or \emph{Reductio ad Absurdum}.\
In a Proof of Contradiction, we establish the validity of the argument
\[
(p_1 \wedge p_2 \wedge \cdots \wedge p_n) \rightarrow q
\]
by establishing the validity of the logically equivalent argument
\[
(p_1 \wedge p_2 \wedge \cdots \wedge p_n \wedge q) \rightarrow F_0.
\] 
We first assume that what we are trying to prove is actually false, then produce a contradiction of the form $s \wedge \neg s$, for some statement $s$. This contradiction concludes that the statement that was assumed to be false is in fact true, and this validates the argument (or completes the proof).
\subsection{Predicate Logic and Quantifiers}
\begin{definition} \emph{A declarative sentence is an }open statement \emph{if}\end{definition}
\begin{enumerate}
\item It contains one or more variables, and
\item It is not a statement, but
\item It becomes a statement when the variables in it are replaced by certain allowable choices.
\end{enumerate}
All of these are open statements: \begin{center}The number $x-5$ is an even integer.\\ $x-5=7$\\$3x+y>7$\end{center}
The allowable choices of variable constitute what is called the \emph{universe}\footnote{This is an example of a \emph{set}} or \emph{universe of discourse} for the open statement. Open statements are denoted by $p(x), q(x, y)$, etc. (also called predicates).

We can \emph{quantify} an open statement with two types of quantifiers:
\begin{enumerate}
\item existential quantifier: $\exists$\\
\begin{tabular} {ll}
$\exists x$: & For some $x$\\
& For at least one $x$\\
& There exists an $x$ such that \dots
\end{tabular}
\item universal quantifier: $\forall$\\
\begin{tabular} {ll}
$\forall x$: & For all $x$\\
& For any $x$\\
& For every $x$
\end{tabular}
\end{enumerate}
Variable $x$ is called a \emph{free} variable in an open statement and a \emph{bound} variable in a quantified open statement.

Let $p(x)$ denote any open statement with a prescribed \emph{nonempty} universe. Then,
\[ \forall x \; p(x) \Rightarrow \exists x \; p(x). \]
\begin{definition} \emph{Let $p(x), q(x)$ be open statements defined for a given universe. \\\indent When the biconditional $p(a) \leftrightarrow q(a)$ is true for each replacement $a$ from the universe (that is, $p(a) \Leftrightarrow q(a)$ for each $a$ in universe), we write $\forall x \; [p(x) \Leftrightarrow q(x)]$.\\\indent If the implication $p \rightarrow q$ is true for each $a$ in the universe (that is, $p(a) \Rightarrow q(a)$ for each $a$ in universe), then we write $\forall x \; [p(x) \Rightarrow q(x)]$.}
\end{definition}
\begin{definition}\emph{For open statements $p(x), q(x)$ --- defined for a prescribed universe --- and the universally quantified statement $\forall x \; [p(x) \rightarrow q(x)]$, we define:}\end{definition}
\begin{tabular} {lclcl}
1) & Contrapositive of &$\forall x \; [p(x) \rightarrow q(x)]$& to be & $\forall x \; [\neg q(x) \rightarrow \neg p(x)]$\\
2) & Converse of &$\forall x \; [p(x) \rightarrow q(x)]$& to be & $\forall x \; [q(x) \rightarrow p(x)]$\\
3) & Inverse of &$\forall x \; [p(x) \rightarrow q(x)]$& to be & $\forall x \; [\neg p(x) \rightarrow \neg q(x)]$\\
\end{tabular}\\

For a prescribed universe and any open statements $p(x), q(x)$ in the variable $x$: 
\[\exists x \; [p(x) \wedge q(x)] \Rightarrow [\exists x \; p(x) \wedge \exists x \; q(x)]\]
\[\exists x \; [p(x) \vee q(x)] \Leftrightarrow [\exists x \; p(x) \vee \exists x \; q(x)]\]
\[\forall x \; [p(x) \wedge q(x)] \Leftrightarrow [\forall x \; p(x) \wedge \forall x \; q(x)]\]
\[\left[\forall x \; p(x) \vee \forall x \; q(x)\right] \Rightarrow \forall x \; [p(x) \vee q(x)]\]
Negation of quantifications:
\[\neg[\forall x \; p(x)] \Leftrightarrow \exists x \; \neg p(x)\]
\[\neg[\exists x \; p(x)] \Leftrightarrow \forall x \; \neg p(x)\]
\section{Sets}
\subsection{Introduction to Sets}
\begin{definition}\emph{A set is a collection of objects. The objects in a set are also called its }members, \emph{or }elements. \emph{A set is said to contain its elements.}
\end{definition}
\begin{itemize}
\item Elements of sets can be related, or completely unrelated.
\item Uppercase letters A, B, C, \dots, S, T, \dots are used to denote sets.
\item Order of elements does not matter.
\item $x \in A$ indicates that $x$ is an element of $A$.
\item $x \notin A$ indicates that $x$ is not an element of $A$.
\end{itemize}
\subsubsection{Infinite Sets}
\begin{itemize}
\item $\mathbb{N} = $ Set of natural numbers%\{1,2,3,\dots\}$
\item $\mathbb{Z} = $ Set of integers
\item $\mathbb{Q} = $ Set of rational numbers
\item $\mathbb{R} = $ Set of real numbers
\end{itemize}
\subsubsection{Set Builder Notation}
\[A = \{x|condition\}\]
The vertical line $|$ is read \emph{such that}, and the symbols $\{x| \dots \}$ are read \emph{the set of all $x$ such that ...\,}.
\begin{definition} \emph{Two sets are equal if and only if they have exactly the same elements.\footnote{$A = \{1,2,3\}$ and $B = \{1,1,2,3,2,3,3\}$ are considered to be the same set.}} \end{definition}
\subsubsection{Cardinality}
\begin{definition} \emph{Let $S$ be a set. If there are exactly $n$ distinct elements in $S$, we say $S$ is a finite set and that $n$ is the cardinality of $n$ denoted by $|S|$.} \end{definition}
\begin{definition} \emph{A set is infinite if it is not finite.} \end{definition}
\subsubsection{Cartesian Product}
\begin{definition} \emph{Let $A$ and $B$ be sets. The cartesian product of $A$ and $B$, denoted by $A\times B$ is the set of all ordered pairs $(a, b)$ where $a \in A$ and $b \in B$.}
\[A \times B = \{ (a, b) | a \in A \wedge b \in B \}\]
\end{definition}
\subsection{Subsets}
\begin{definition}
\emph{Set $A$ is said to be a subset of $B$ if and only if every element of $A$ is also an element of $B$. We use $A \subseteq B$ to indicate that $A$ is a subset of $B$. In predicate logic,} 
\[A \subseteq B \leftrightarrow \forall x \; [x \in A \rightarrow x \in B].\]
\end{definition}
\begin{itemize}
\item $A \subset B$ means $A$ is a proper subset of $B$ when $(A \subseteq B) \wedge (A \neq B)$
\item To show that $A=B$, we show that $(A \subseteq B) \wedge (B \subseteq A)$.
\end{itemize}
\begin{definition}\emph{The }null set, \emph{or }empty set, \emph{is the set containing no elements. It is denoted by $\emptyset$ or \{ \}.}\end{definition}
\subsubsection{The Power Set}
\begin{definition} \emph{Given a set $S$, the }power set \emph{of $S$ is the set of all subsets of $S$. We denote this by $P(S)$\footnote{In some computer science books $2^A$ is used for $P(A)$.}.}\end{definition}
For any finite set $A$ with $|A| = n \geq 0$, $A$ has $2^n$ subsets and $|P(A)| = 2^n$.
\subsection{Set Operations}
\begin{definition} \emph{For $A, B \subseteq U$, we define the following:}
\begin{itemize}
\item $A \cup B = \{x|x \in A \vee x \in B\}$
\item $A \cap B = \{x|x \in A \wedge x \in B\}$
\item $A \bigtriangleup B = \{x|x \in A \cup B \wedge x \notin A \cap B\}$
\end{itemize}
\end{definition}
\begin{definition}\emph{Let $S, T \subseteq U$. The sets $S$ and $T$ are called }disjoint, \emph{or }mutually disjoint, \emph{when $S \cap T = \emptyset$.}\end{definition}
\begin{definition}\emph{For a set $A \subseteq U$, the }complement \emph{of $A$, denoted $U-A$, or $\overline{A}$, is given by $\{x|x\in U \wedge x \notin A\}$}\end{definition}
\begin{center}
\textbf{The Laws of Set Theory}
\end{center}
\begin{tabular}  {c l l}
1) & $\overline{\overline{A}} = A$ & Law of Double Complement\\
2) & $\overline{A \cup B} = \overline{A} \cap \overline{B}$ & DeMorgan's Laws\\
& $\overline{A \cap B} = \overline{A} \cup \overline{B}$\\
3) & $A \cup B = B \cup A$ & Commutative Laws\\
& $A \cap B = B \cap A$\\
4) & $A \cup (B \cup C) = (A \cup B) \cup C$ & Associative Laws\\
& $A \cap (B \cap C) = (A \cap B) \cap C$\\
5) & $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ & Distributive Laws\\
& $A \cap (B \cup C) = (A \cap B) \cup (A \cap C))$\\
6) & $A \cup A = A$ & Idempotent Laws\\
& $A \cap A = A$\\
7) & $A \cup \emptyset = A$ & Identity Laws\\
& $A \cap U = A$\\
8) & $A \cup \overline{A} = U$ & Inverse Laws\\
& $A \cap \overline{A} = \emptyset$\\
9) & $A \cup U = U$ & Domination Laws\\
& $A \cap \emptyset = \emptyset$\\
10) & $A \cup (A \cap B) = A$ & Absorption Laws\\
& $A \cap (A \cup B) = A$
\end{tabular}
\begin{definition}
\emph{Let $s$ be a statement dealing with the equality of two set expressions. The }dual \emph{of $s$, denoted $s^d$, is obtained from replacing (1) each occurrence of $\emptyset$ and $U$ by $U$ and $\emptyset$, respectively; and (2) each occurrence of $\cap$ and $\cup$ by $\cup$ and $\cap$, respectively.}
\end{definition}
\begin{theorem}
The Principle of Duality. \emph{Let $s$ be a theorem dealing with the equality of two set expressions. Then $s^d$, the dual of $s$, is also a theorem.}
\end{theorem}
\section{Properties of the Integers: Mathematical Induction}
\subsection{The Well-Ordering Principle}
\begin{definition}The Well-Ordering Principle. \emph{Every }nonempty \emph{subset of $\mathbb{Z}^+$ contains a smallest element. ($\mathbb{Z}^+$ is} well ordered.)
\[\forall X \subseteq \mathbb{Z}^+ \wedge x \neq \emptyset \; \exists a \in X \; |\; \forall x \in X, a \subseteq x\]
is this right..?
\end{definition}
We can express the set $\mathbb{Z}^+$ using the inequality symbol $\geq$:
\[\mathbb{Z}^+ = \{x \in \mathbb{Z} | x > 0\} = \{x \in \mathbb{Z} | x \geq 1\}.\]
You cannot with $\mathbb{Q}^+$ and $\mathbb{R}^+$ because they are not well ordered. If $q$ is a positive rational number, then since $0 < q/2 < q$, we would have a smaller positive rational number $q/2$.
\begin{theorem}The Principle of Mathematical Induction. \begin{em}Let $S(n)$ denote an open mathematical statement that involves one or more occurrences of the variable $n$, which represents a positive integer.
\begin{enumerate} [(a)]
\item If $S(1)$ is true; and
\item If whenever $S(k)$ is true (for some particular, but arbitrarily chosen, $k \in \mathbb{Z}^+$), then $S(k+1)$ is true;
\end{enumerate}
then $S(n)$ is true for all $n \in \mathbb{Z}^+$.\\
\emph{Proof.} Let $S(n)$ be such an open statement satisfying conditions (a) and (b), and let $F = \{t \in \mathbb{Z}^+ | S(t) \text{ is false}\}$. We wish to prove that $F=\emptyset$, so to obtain a contradiction we assume that $F\neq\emptyset$. Then by the Well-Ordering Principle, $F$ has a least element $m$. Since $S(1)$ is true, it follows that $m \neq 1$, so $m > 1$, and consequently $m - 1 \notin F$, we have $S(m-1)$ true. So by condition (b) it follows that $S((m-1)+1) = S(m)$ is true, contradicting $m \in F$. This contradiction arose from the assumption that $F \neq \emptyset$. Consequently, $F = \emptyset$.
\end{em}
\end{theorem}
\end{document}